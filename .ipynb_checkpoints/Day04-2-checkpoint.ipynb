{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "satellite-tsunami",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "social-forwarding",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation # 특수문자 제거용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unauthorized-salon",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import numpy as np\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "driven-vienna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>articleID</th>\n",
       "      <th>articleWordCount</th>\n",
       "      <th>byline</th>\n",
       "      <th>documentType</th>\n",
       "      <th>headline</th>\n",
       "      <th>keywords</th>\n",
       "      <th>multimedia</th>\n",
       "      <th>newDesk</th>\n",
       "      <th>printPage</th>\n",
       "      <th>pubDate</th>\n",
       "      <th>sectionName</th>\n",
       "      <th>snippet</th>\n",
       "      <th>source</th>\n",
       "      <th>typeOfMaterial</th>\n",
       "      <th>webURL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5adf6684068401528a2aa69b</td>\n",
       "      <td>781</td>\n",
       "      <td>By JOHN BRANCH</td>\n",
       "      <td>article</td>\n",
       "      <td>Former N.F.L. Cheerleaders’ Settlement Offer: ...</td>\n",
       "      <td>['Workplace Hazards and Violations', 'Football...</td>\n",
       "      <td>68</td>\n",
       "      <td>Sports</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:16:49</td>\n",
       "      <td>Pro Football</td>\n",
       "      <td>“I understand that they could meet with us, pa...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/sports/foot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5adf653f068401528a2aa697</td>\n",
       "      <td>656</td>\n",
       "      <td>By LISA FRIEDMAN</td>\n",
       "      <td>article</td>\n",
       "      <td>E.P.A. to Unveil a New Rule. Its Effect: Less ...</td>\n",
       "      <td>['Environmental Protection Agency', 'Pruitt, S...</td>\n",
       "      <td>68</td>\n",
       "      <td>Climate</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 17:11:21</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>The agency plans to publish a new regulation T...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/climate/epa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5adf4626068401528a2aa628</td>\n",
       "      <td>2427</td>\n",
       "      <td>By PETE WELLS</td>\n",
       "      <td>article</td>\n",
       "      <td>The New Noma, Explained</td>\n",
       "      <td>['Restaurants', 'Noma (Copenhagen, Restaurant)...</td>\n",
       "      <td>66</td>\n",
       "      <td>Dining</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-04-24 14:58:44</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>What’s it like to eat at the second incarnatio...</td>\n",
       "      <td>The New York Times</td>\n",
       "      <td>News</td>\n",
       "      <td>https://www.nytimes.com/2018/04/24/dining/noma...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  articleID  articleWordCount            byline documentType  \\\n",
       "0  5adf6684068401528a2aa69b               781    By JOHN BRANCH      article   \n",
       "1  5adf653f068401528a2aa697               656  By LISA FRIEDMAN      article   \n",
       "2  5adf4626068401528a2aa628              2427     By PETE WELLS      article   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Former N.F.L. Cheerleaders’ Settlement Offer: ...   \n",
       "1  E.P.A. to Unveil a New Rule. Its Effect: Less ...   \n",
       "2                            The New Noma, Explained   \n",
       "\n",
       "                                            keywords  multimedia  newDesk  \\\n",
       "0  ['Workplace Hazards and Violations', 'Football...          68   Sports   \n",
       "1  ['Environmental Protection Agency', 'Pruitt, S...          68  Climate   \n",
       "2  ['Restaurants', 'Noma (Copenhagen, Restaurant)...          66   Dining   \n",
       "\n",
       "   printPage              pubDate   sectionName  \\\n",
       "0          0  2018-04-24 17:16:49  Pro Football   \n",
       "1          0  2018-04-24 17:11:21       Unknown   \n",
       "2          0  2018-04-24 14:58:44       Unknown   \n",
       "\n",
       "                                             snippet              source  \\\n",
       "0  “I understand that they could meet with us, pa...  The New York Times   \n",
       "1  The agency plans to publish a new regulation T...  The New York Times   \n",
       "2  What’s it like to eat at the second incarnatio...  The New York Times   \n",
       "\n",
       "  typeOfMaterial                                             webURL  \n",
       "0           News  https://www.nytimes.com/2018/04/24/sports/foot...  \n",
       "1           News  https://www.nytimes.com/2018/04/24/climate/epa...  \n",
       "2           News  https://www.nytimes.com/2018/04/24/dining/noma...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('ArticlesApril2018.csv')\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "perfect-spare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1324 entries, 0 to 1323\n",
      "Data columns (total 15 columns):\n",
      " #   Column            Non-Null Count  Dtype \n",
      "---  ------            --------------  ----- \n",
      " 0   articleID         1324 non-null   object\n",
      " 1   articleWordCount  1324 non-null   int64 \n",
      " 2   byline            1324 non-null   object\n",
      " 3   documentType      1324 non-null   object\n",
      " 4   headline          1324 non-null   object\n",
      " 5   keywords          1324 non-null   object\n",
      " 6   multimedia        1324 non-null   int64 \n",
      " 7   newDesk           1324 non-null   object\n",
      " 8   printPage         1324 non-null   int64 \n",
      " 9   pubDate           1324 non-null   object\n",
      " 10  sectionName       1324 non-null   object\n",
      " 11  snippet           1324 non-null   object\n",
      " 12  source            1324 non-null   object\n",
      " 13  typeOfMaterial    1324 non-null   object\n",
      " 14  webURL            1324 non-null   object\n",
      "dtypes: int64(3), object(12)\n",
      "memory usage: 155.3+ KB\n"
     ]
    }
   ],
   "source": [
    "# 한눈에 보기 어려우므로\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "parallel-marketing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사용할 열인 제목에 해당되는 headline 열에 Null값이 있는지 확인\n",
    "df['headline'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "hollow-grounds",
   "metadata": {},
   "outputs": [],
   "source": [
    "headline= [] # 리스트 선언\n",
    "# append를 하면 리스트 안의 리스트 형태가 되지만,\n",
    "headline.append(list(df.headline.values))\n",
    "# headline[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "massive-conviction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
       " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
       " 'The New Noma, Explained',\n",
       " 'Unknown',\n",
       " 'Unknown']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extend를 하면 리스로 깔끔하게 정리됨\n",
    "headline = []\n",
    "headline.extend(list(df.headline.values))\n",
    "headline[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "voluntary-garlic",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 샘플의 개수 : 1324\n"
     ]
    }
   ],
   "source": [
    "print('총 샘플의 개수 : {}'.format(len(headline))) # 현재 샘플의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "deadly-reputation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "노이즈값 제거 후 샘플의 개수 : 1214\n"
     ]
    }
   ],
   "source": [
    "headline = [n for n in headline if n != \"Unknown\"] # Unknown 값을 가진 샘플 제거\n",
    "print('노이즈값 제거 후 샘플의 개수 : {}'.format(len(headline))) # 제거 후 샘플의 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "falling-vermont",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Former N.F.L. Cheerleaders’ Settlement Offer: $1 and a Meeting With Goodell',\n",
       " 'E.P.A. to Unveil a New Rule. Its Effect: Less Science in Policymaking.',\n",
       " 'The New Noma, Explained',\n",
       " 'How a Bag of Texas Dirt  Became a Times Tradition',\n",
       " 'Is School a Place for Self-Expression?']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 'Unknown' 제거 확인\n",
    "headline[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "protecting-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리. 구두점 제거와 단어의 소문자화\n",
    "def repreprocessing(s):\n",
    "    s = s.encode(\"utf8\").decode(\"ascii\", 'ignore')\n",
    "    return ''.join(c for c in s if c not in punctuation).lower()\n",
    "    # 구두점 제거와 소문자화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "documentary-transparency",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['former nfl cheerleaders settlement offer 1 and a meeting with goodell',\n",
       " 'epa to unveil a new rule its effect less science in policymaking',\n",
       " 'the new noma explained',\n",
       " 'how a bag of texas dirt  became a times tradition',\n",
       " 'is school a place for selfexpression']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = [repreprocessing(x) for x in headline]\n",
    "text[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "italic-glenn",
   "metadata": {},
   "source": [
    "### 불용어 처리를 하면 안 되는 이유\n",
    "### RNN은 인접한 단어간의 관계가 중요하기 때문!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "attractive-booking",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "단어 집합의 크기 : 3494\n"
     ]
    }
   ],
   "source": [
    "t = Tokenizer()\n",
    "t.fit_on_texts(text)\n",
    "vocab_size = len(t.word_index) + 1\n",
    "print('단어 집합의 크기 : %d' % vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "focused-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수 인코딩. 숫자화. 하나의 문장을 여러 줄로 분해하여 훈련 데이터 구성\n",
    "sequences = list()\n",
    "\n",
    "for line in text:\n",
    "    encoded = t.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(encoded)):\n",
    "        sequence = encoded[:i+1]\n",
    "        sequences.append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "needed-ceremony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[99, 269],\n",
       " [99, 269, 371],\n",
       " [99, 269, 371, 1115],\n",
       " [99, 269, 371, 1115, 582],\n",
       " [99, 269, 371, 1115, 582, 52],\n",
       " [99, 269, 371, 1115, 582, 52, 7],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10],\n",
       " [99, 269, 371, 1115, 582, 52, 7, 2, 372, 10, 1116],\n",
       " [100, 3]]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:11] # 11개의 샘플 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "confirmed-fighter",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7803"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "labeled-capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 만들기\n",
    "index_to_word = {}\n",
    "for key, value in t.word_index.items(): # 인덱스와 단어 바꾸기\n",
    "    index_to_word[value] = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "unknown-puppy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빈도수 상위 582번 단어 : offer\n"
     ]
    }
   ],
   "source": [
    "print('빈도수 상위 582번 단어 : {}'.format(index_to_word[582]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dedicated-story",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "빈도수 상위 3번 단어 : to\n"
     ]
    }
   ],
   "source": [
    "print('빈도수 상위 3번 단어 : {}'.format(index_to_word[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "particular-strike",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = max(len(l) for l in sequences)\n",
    "# 샘플의 최대 길이\n",
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "parliamentary-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최대 길이 24로 모든 샘플 패딩\n",
    "sequences = pad_sequences(sequences, maxlen=max_len, padding='pre')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "million-effectiveness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "          99,  269],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,   99,\n",
       "         269,  371],\n",
       "       [   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,   99,  269,\n",
       "         371, 1115]], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "common-meaning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature와 label분리를 위해 numpy 이용\n",
    "sequences = np.array(sequences)\n",
    "X = sequences[:, :-1]\n",
    "y = sequences[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "yellow-cedar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,  99],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,  99, 269],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,  99, 269, 371]], dtype=int32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "hungry-islam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 269,  371, 1115], dtype=int32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "decent-adelaide",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 레이블 원-핫 인코딩\n",
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "congressional-authentication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "rotary-mainland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3494"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "suffering-tunisia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "raising-laptop",
   "metadata": {},
   "source": [
    "### 모델 설계하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "diverse-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "closed-processor",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "244/244 - 5s - loss: 7.6415 - accuracy: 0.0273\n",
      "Epoch 2/200\n",
      "244/244 - 5s - loss: 7.1033 - accuracy: 0.0279\n",
      "Epoch 3/200\n",
      "244/244 - 5s - loss: 6.9708 - accuracy: 0.0340\n",
      "Epoch 4/200\n",
      "244/244 - 5s - loss: 6.8394 - accuracy: 0.0422\n",
      "Epoch 5/200\n",
      "244/244 - 5s - loss: 6.6825 - accuracy: 0.0464\n",
      "Epoch 6/200\n",
      "244/244 - 5s - loss: 6.4941 - accuracy: 0.0523\n",
      "Epoch 7/200\n",
      "244/244 - 5s - loss: 6.2905 - accuracy: 0.0568\n",
      "Epoch 8/200\n",
      "244/244 - 5s - loss: 6.0840 - accuracy: 0.0609\n",
      "Epoch 9/200\n",
      "244/244 - 5s - loss: 5.8818 - accuracy: 0.0639\n",
      "Epoch 10/200\n",
      "244/244 - 5s - loss: 5.6941 - accuracy: 0.0691\n",
      "Epoch 11/200\n",
      "244/244 - 5s - loss: 5.5129 - accuracy: 0.0732\n",
      "Epoch 12/200\n",
      "244/244 - 5s - loss: 5.3443 - accuracy: 0.0775\n",
      "Epoch 13/200\n",
      "244/244 - 5s - loss: 5.1851 - accuracy: 0.0848\n",
      "Epoch 14/200\n",
      "244/244 - 5s - loss: 5.0306 - accuracy: 0.0947\n",
      "Epoch 15/200\n",
      "244/244 - 5s - loss: 4.8851 - accuracy: 0.1029\n",
      "Epoch 16/200\n",
      "244/244 - 5s - loss: 4.7477 - accuracy: 0.1151\n",
      "Epoch 17/200\n",
      "244/244 - 5s - loss: 4.6147 - accuracy: 0.1353\n",
      "Epoch 18/200\n",
      "244/244 - 5s - loss: 4.4872 - accuracy: 0.1462\n",
      "Epoch 19/200\n",
      "244/244 - 5s - loss: 4.3641 - accuracy: 0.1622\n",
      "Epoch 20/200\n",
      "244/244 - 5s - loss: 4.2465 - accuracy: 0.1767\n",
      "Epoch 21/200\n",
      "244/244 - 5s - loss: 4.1307 - accuracy: 0.1949\n",
      "Epoch 22/200\n",
      "244/244 - 5s - loss: 4.0215 - accuracy: 0.2111\n",
      "Epoch 23/200\n",
      "244/244 - 5s - loss: 3.9132 - accuracy: 0.2271\n",
      "Epoch 24/200\n",
      "244/244 - 5s - loss: 3.8092 - accuracy: 0.2445\n",
      "Epoch 25/200\n",
      "244/244 - 5s - loss: 3.7089 - accuracy: 0.2612\n",
      "Epoch 26/200\n",
      "244/244 - 5s - loss: 3.6132 - accuracy: 0.2773\n",
      "Epoch 27/200\n",
      "244/244 - 5s - loss: 3.5194 - accuracy: 0.2928\n",
      "Epoch 28/200\n",
      "244/244 - 5s - loss: 3.4262 - accuracy: 0.3128\n",
      "Epoch 29/200\n",
      "244/244 - 5s - loss: 3.3428 - accuracy: 0.3264\n",
      "Epoch 30/200\n",
      "244/244 - 5s - loss: 3.2580 - accuracy: 0.3442\n",
      "Epoch 31/200\n",
      "244/244 - 5s - loss: 3.1749 - accuracy: 0.3578\n",
      "Epoch 32/200\n",
      "244/244 - 5s - loss: 3.0971 - accuracy: 0.3786\n",
      "Epoch 33/200\n",
      "244/244 - 5s - loss: 3.0249 - accuracy: 0.3847\n",
      "Epoch 34/200\n",
      "244/244 - 5s - loss: 2.9481 - accuracy: 0.3978\n",
      "Epoch 35/200\n",
      "244/244 - 5s - loss: 2.8800 - accuracy: 0.4102\n",
      "Epoch 36/200\n",
      "244/244 - 5s - loss: 2.8143 - accuracy: 0.4220\n",
      "Epoch 37/200\n",
      "244/244 - 5s - loss: 2.7467 - accuracy: 0.4370\n",
      "Epoch 38/200\n",
      "244/244 - 5s - loss: 2.6842 - accuracy: 0.4494\n",
      "Epoch 39/200\n",
      "244/244 - 5s - loss: 2.6233 - accuracy: 0.4611\n",
      "Epoch 40/200\n",
      "244/244 - 5s - loss: 2.5661 - accuracy: 0.4729\n",
      "Epoch 41/200\n",
      "244/244 - 5s - loss: 2.5117 - accuracy: 0.4814\n",
      "Epoch 42/200\n",
      "244/244 - 5s - loss: 2.4525 - accuracy: 0.4933\n",
      "Epoch 43/200\n",
      "244/244 - 5s - loss: 2.4012 - accuracy: 0.5047\n",
      "Epoch 44/200\n",
      "244/244 - 5s - loss: 2.3496 - accuracy: 0.5151\n",
      "Epoch 45/200\n",
      "244/244 - 5s - loss: 2.2981 - accuracy: 0.5193\n",
      "Epoch 46/200\n",
      "244/244 - 5s - loss: 2.2495 - accuracy: 0.5334\n",
      "Epoch 47/200\n",
      "244/244 - 5s - loss: 2.2027 - accuracy: 0.5407\n",
      "Epoch 48/200\n",
      "244/244 - 5s - loss: 2.1562 - accuracy: 0.5554\n",
      "Epoch 49/200\n",
      "244/244 - 5s - loss: 2.1106 - accuracy: 0.5616\n",
      "Epoch 50/200\n",
      "244/244 - 5s - loss: 2.0685 - accuracy: 0.5694\n",
      "Epoch 51/200\n",
      "244/244 - 5s - loss: 2.0239 - accuracy: 0.5840\n",
      "Epoch 52/200\n",
      "244/244 - 5s - loss: 1.9829 - accuracy: 0.5885\n",
      "Epoch 53/200\n",
      "244/244 - 5s - loss: 1.9417 - accuracy: 0.5952\n",
      "Epoch 54/200\n",
      "244/244 - 5s - loss: 1.9021 - accuracy: 0.6045\n",
      "Epoch 55/200\n",
      "244/244 - 5s - loss: 1.8628 - accuracy: 0.6155\n",
      "Epoch 56/200\n",
      "244/244 - 5s - loss: 1.8222 - accuracy: 0.6228\n",
      "Epoch 57/200\n",
      "244/244 - 5s - loss: 1.7864 - accuracy: 0.6307\n",
      "Epoch 58/200\n",
      "244/244 - 5s - loss: 1.7481 - accuracy: 0.6404\n",
      "Epoch 59/200\n",
      "244/244 - 5s - loss: 1.7140 - accuracy: 0.6474\n",
      "Epoch 60/200\n",
      "244/244 - 5s - loss: 1.6775 - accuracy: 0.6539\n",
      "Epoch 61/200\n",
      "244/244 - 5s - loss: 1.6396 - accuracy: 0.6624\n",
      "Epoch 62/200\n",
      "244/244 - 5s - loss: 1.6059 - accuracy: 0.6703\n",
      "Epoch 63/200\n",
      "244/244 - 5s - loss: 1.5725 - accuracy: 0.6769\n",
      "Epoch 64/200\n",
      "244/244 - 5s - loss: 1.5390 - accuracy: 0.6828\n",
      "Epoch 65/200\n",
      "244/244 - 5s - loss: 1.5071 - accuracy: 0.6938\n",
      "Epoch 66/200\n",
      "244/244 - 5s - loss: 1.4760 - accuracy: 0.6991\n",
      "Epoch 67/200\n",
      "244/244 - 5s - loss: 1.4458 - accuracy: 0.7049\n",
      "Epoch 68/200\n",
      "244/244 - 5s - loss: 1.4127 - accuracy: 0.7146\n",
      "Epoch 69/200\n",
      "244/244 - 5s - loss: 1.3827 - accuracy: 0.7204\n",
      "Epoch 70/200\n",
      "244/244 - 5s - loss: 1.3549 - accuracy: 0.7247\n",
      "Epoch 71/200\n",
      "244/244 - 5s - loss: 1.3271 - accuracy: 0.7325\n",
      "Epoch 72/200\n",
      "244/244 - 5s - loss: 1.2972 - accuracy: 0.7393\n",
      "Epoch 73/200\n",
      "244/244 - 5s - loss: 1.2711 - accuracy: 0.7442\n",
      "Epoch 74/200\n",
      "244/244 - 5s - loss: 1.2420 - accuracy: 0.7493\n",
      "Epoch 75/200\n",
      "244/244 - 5s - loss: 1.2145 - accuracy: 0.7565\n",
      "Epoch 76/200\n",
      "244/244 - 5s - loss: 1.1891 - accuracy: 0.7606\n",
      "Epoch 77/200\n",
      "244/244 - 5s - loss: 1.1636 - accuracy: 0.7651\n",
      "Epoch 78/200\n",
      "244/244 - 5s - loss: 1.1375 - accuracy: 0.7742\n",
      "Epoch 79/200\n",
      "244/244 - 5s - loss: 1.1132 - accuracy: 0.7783\n",
      "Epoch 80/200\n",
      "244/244 - 5s - loss: 1.0905 - accuracy: 0.7837\n",
      "Epoch 81/200\n",
      "244/244 - 5s - loss: 1.0647 - accuracy: 0.7876\n",
      "Epoch 82/200\n",
      "244/244 - 5s - loss: 1.0407 - accuracy: 0.7933\n",
      "Epoch 83/200\n",
      "244/244 - 5s - loss: 1.0212 - accuracy: 0.7965\n",
      "Epoch 84/200\n",
      "244/244 - 5s - loss: 0.9971 - accuracy: 0.8034\n",
      "Epoch 85/200\n",
      "244/244 - 5s - loss: 0.9761 - accuracy: 0.8047\n",
      "Epoch 86/200\n",
      "244/244 - 5s - loss: 0.9533 - accuracy: 0.8116\n",
      "Epoch 87/200\n",
      "244/244 - 5s - loss: 0.9328 - accuracy: 0.8110\n",
      "Epoch 88/200\n",
      "244/244 - 5s - loss: 0.9120 - accuracy: 0.8199\n",
      "Epoch 89/200\n",
      "244/244 - 5s - loss: 0.8939 - accuracy: 0.8226\n",
      "Epoch 90/200\n",
      "244/244 - 5s - loss: 0.8729 - accuracy: 0.8246\n",
      "Epoch 91/200\n",
      "244/244 - 5s - loss: 0.8540 - accuracy: 0.8288\n",
      "Epoch 92/200\n",
      "244/244 - 5s - loss: 0.8353 - accuracy: 0.8320\n",
      "Epoch 93/200\n",
      "244/244 - 5s - loss: 0.8171 - accuracy: 0.8372\n",
      "Epoch 94/200\n",
      "244/244 - 5s - loss: 0.8005 - accuracy: 0.8407\n",
      "Epoch 95/200\n",
      "244/244 - 5s - loss: 0.7825 - accuracy: 0.8415\n",
      "Epoch 96/200\n",
      "244/244 - 5s - loss: 0.7647 - accuracy: 0.8485\n",
      "Epoch 97/200\n",
      "244/244 - 5s - loss: 0.7493 - accuracy: 0.8472\n",
      "Epoch 98/200\n",
      "244/244 - 5s - loss: 0.7332 - accuracy: 0.8522\n",
      "Epoch 99/200\n",
      "244/244 - 5s - loss: 0.7213 - accuracy: 0.8553\n",
      "Epoch 100/200\n",
      "244/244 - 5s - loss: 0.7020 - accuracy: 0.8568\n",
      "Epoch 101/200\n",
      "244/244 - 5s - loss: 0.6864 - accuracy: 0.8633\n",
      "Epoch 102/200\n",
      "244/244 - 5s - loss: 0.6714 - accuracy: 0.8651\n",
      "Epoch 103/200\n",
      "244/244 - 5s - loss: 0.6563 - accuracy: 0.8688\n",
      "Epoch 104/200\n",
      "244/244 - 5s - loss: 0.6444 - accuracy: 0.8688\n",
      "Epoch 105/200\n",
      "244/244 - 5s - loss: 0.6294 - accuracy: 0.8729\n",
      "Epoch 106/200\n",
      "244/244 - 5s - loss: 0.6188 - accuracy: 0.8724\n",
      "Epoch 107/200\n",
      "244/244 - 5s - loss: 0.6051 - accuracy: 0.8761\n",
      "Epoch 108/200\n",
      "244/244 - 5s - loss: 0.5945 - accuracy: 0.8803\n",
      "Epoch 109/200\n",
      "244/244 - 5s - loss: 0.5807 - accuracy: 0.8827\n",
      "Epoch 110/200\n",
      "244/244 - 5s - loss: 0.5697 - accuracy: 0.8815\n",
      "Epoch 111/200\n",
      "244/244 - 5s - loss: 0.5584 - accuracy: 0.8854\n",
      "Epoch 112/200\n",
      "244/244 - 5s - loss: 0.5460 - accuracy: 0.8840\n",
      "Epoch 113/200\n",
      "244/244 - 5s - loss: 0.5367 - accuracy: 0.8894\n",
      "Epoch 114/200\n",
      "244/244 - 5s - loss: 0.5273 - accuracy: 0.8902\n",
      "Epoch 115/200\n",
      "244/244 - 5s - loss: 0.5180 - accuracy: 0.8909\n",
      "Epoch 116/200\n",
      "244/244 - 5s - loss: 0.5173 - accuracy: 0.8947\n",
      "Epoch 117/200\n",
      "244/244 - 5s - loss: 0.4976 - accuracy: 0.8948\n",
      "Epoch 118/200\n",
      "244/244 - 5s - loss: 0.4859 - accuracy: 0.8961\n",
      "Epoch 119/200\n",
      "244/244 - 5s - loss: 0.4757 - accuracy: 0.9002\n",
      "Epoch 120/200\n",
      "244/244 - 5s - loss: 0.4670 - accuracy: 0.9002\n",
      "Epoch 121/200\n",
      "244/244 - 5s - loss: 0.4600 - accuracy: 0.8981\n",
      "Epoch 122/200\n",
      "244/244 - 5s - loss: 0.4529 - accuracy: 0.9013\n",
      "Epoch 123/200\n",
      "244/244 - 5s - loss: 0.4471 - accuracy: 0.9031\n",
      "Epoch 124/200\n",
      "244/244 - 5s - loss: 0.4390 - accuracy: 0.9039\n",
      "Epoch 125/200\n",
      "244/244 - 5s - loss: 0.4295 - accuracy: 0.9038\n",
      "Epoch 126/200\n",
      "244/244 - 5s - loss: 0.4227 - accuracy: 0.9052\n",
      "Epoch 127/200\n",
      "244/244 - 5s - loss: 0.4151 - accuracy: 0.9055\n",
      "Epoch 128/200\n",
      "244/244 - 5s - loss: 0.4096 - accuracy: 0.9076\n",
      "Epoch 129/200\n",
      "244/244 - 5s - loss: 0.4032 - accuracy: 0.9076\n",
      "Epoch 130/200\n",
      "244/244 - 5s - loss: 0.3960 - accuracy: 0.9084\n",
      "Epoch 131/200\n",
      "244/244 - 5s - loss: 0.3925 - accuracy: 0.9091\n",
      "Epoch 132/200\n",
      "244/244 - 5s - loss: 0.3856 - accuracy: 0.9100\n",
      "Epoch 133/200\n",
      "244/244 - 5s - loss: 0.3800 - accuracy: 0.9093\n",
      "Epoch 134/200\n",
      "244/244 - 5s - loss: 0.3763 - accuracy: 0.9114\n",
      "Epoch 135/200\n",
      "244/244 - 5s - loss: 0.3738 - accuracy: 0.9112\n",
      "Epoch 136/200\n",
      "244/244 - 5s - loss: 0.3669 - accuracy: 0.9108\n",
      "Epoch 137/200\n",
      "244/244 - 5s - loss: 0.3614 - accuracy: 0.9117\n",
      "Epoch 138/200\n",
      "244/244 - 5s - loss: 0.3572 - accuracy: 0.9121\n",
      "Epoch 139/200\n",
      "244/244 - 5s - loss: 0.3612 - accuracy: 0.9109\n",
      "Epoch 140/200\n",
      "244/244 - 5s - loss: 0.3540 - accuracy: 0.9123\n",
      "Epoch 141/200\n",
      "244/244 - 5s - loss: 0.3434 - accuracy: 0.9141\n",
      "Epoch 142/200\n",
      "244/244 - 5s - loss: 0.3390 - accuracy: 0.9131\n",
      "Epoch 143/200\n",
      "244/244 - 5s - loss: 0.3347 - accuracy: 0.9141\n",
      "Epoch 144/200\n",
      "244/244 - 5s - loss: 0.3332 - accuracy: 0.9135\n",
      "Epoch 145/200\n",
      "244/244 - 5s - loss: 0.3344 - accuracy: 0.9131\n",
      "Epoch 146/200\n",
      "244/244 - 5s - loss: 0.3409 - accuracy: 0.9130\n",
      "Epoch 147/200\n",
      "244/244 - 5s - loss: 0.3307 - accuracy: 0.9138\n",
      "Epoch 148/200\n",
      "244/244 - 5s - loss: 0.3279 - accuracy: 0.9130\n",
      "Epoch 149/200\n",
      "244/244 - 5s - loss: 0.3187 - accuracy: 0.9161\n",
      "Epoch 150/200\n",
      "244/244 - 5s - loss: 0.3153 - accuracy: 0.9166\n",
      "Epoch 151/200\n",
      "244/244 - 5s - loss: 0.3115 - accuracy: 0.9150\n",
      "Epoch 152/200\n",
      "244/244 - 5s - loss: 0.3263 - accuracy: 0.9136\n",
      "Epoch 153/200\n",
      "244/244 - 5s - loss: 0.3111 - accuracy: 0.9158\n",
      "Epoch 154/200\n",
      "244/244 - 5s - loss: 0.3059 - accuracy: 0.9161\n",
      "Epoch 155/200\n",
      "244/244 - 5s - loss: 0.3034 - accuracy: 0.9167\n",
      "Epoch 156/200\n",
      "244/244 - 5s - loss: 0.3032 - accuracy: 0.9159\n",
      "Epoch 157/200\n",
      "244/244 - 5s - loss: 0.3008 - accuracy: 0.9152\n",
      "Epoch 158/200\n",
      "244/244 - 5s - loss: 0.2992 - accuracy: 0.9164\n",
      "Epoch 159/200\n",
      "244/244 - 5s - loss: 0.2971 - accuracy: 0.9155\n",
      "Epoch 160/200\n",
      "244/244 - 5s - loss: 0.2960 - accuracy: 0.9170\n",
      "Epoch 161/200\n",
      "244/244 - 5s - loss: 0.2946 - accuracy: 0.9145\n",
      "Epoch 162/200\n",
      "244/244 - 5s - loss: 0.2919 - accuracy: 0.9158\n",
      "Epoch 163/200\n",
      "244/244 - 5s - loss: 0.2912 - accuracy: 0.9154\n",
      "Epoch 164/200\n",
      "244/244 - 5s - loss: 0.2933 - accuracy: 0.9148\n",
      "Epoch 165/200\n",
      "244/244 - 5s - loss: 0.3019 - accuracy: 0.9152\n",
      "Epoch 166/200\n",
      "244/244 - 5s - loss: 0.2966 - accuracy: 0.9155\n",
      "Epoch 167/200\n",
      "244/244 - 5s - loss: 0.2886 - accuracy: 0.9155\n",
      "Epoch 168/200\n",
      "244/244 - 5s - loss: 0.2841 - accuracy: 0.9163\n",
      "Epoch 169/200\n",
      "244/244 - 5s - loss: 0.2821 - accuracy: 0.9168\n",
      "Epoch 170/200\n",
      "244/244 - 5s - loss: 0.2815 - accuracy: 0.9163\n",
      "Epoch 171/200\n",
      "244/244 - 5s - loss: 0.2809 - accuracy: 0.9163\n",
      "Epoch 172/200\n",
      "244/244 - 5s - loss: 0.2801 - accuracy: 0.9168\n",
      "Epoch 173/200\n",
      "244/244 - 5s - loss: 0.2782 - accuracy: 0.9162\n",
      "Epoch 174/200\n",
      "244/244 - 5s - loss: 0.2779 - accuracy: 0.9181\n",
      "Epoch 175/200\n",
      "244/244 - 5s - loss: 0.2788 - accuracy: 0.9164\n",
      "Epoch 176/200\n",
      "244/244 - 5s - loss: 0.2837 - accuracy: 0.9170\n",
      "Epoch 177/200\n",
      "244/244 - 5s - loss: 0.2822 - accuracy: 0.9145\n",
      "Epoch 178/200\n",
      "244/244 - 5s - loss: 0.2760 - accuracy: 0.9167\n",
      "Epoch 179/200\n",
      "244/244 - 5s - loss: 0.2729 - accuracy: 0.9164\n",
      "Epoch 180/200\n",
      "244/244 - 5s - loss: 0.2726 - accuracy: 0.9161\n",
      "Epoch 181/200\n",
      "244/244 - 5s - loss: 0.2718 - accuracy: 0.9179\n",
      "Epoch 182/200\n",
      "244/244 - 5s - loss: 0.2713 - accuracy: 0.9162\n",
      "Epoch 183/200\n",
      "244/244 - 5s - loss: 0.2717 - accuracy: 0.9181\n",
      "Epoch 184/200\n",
      "244/244 - 5s - loss: 0.2754 - accuracy: 0.9161\n",
      "Epoch 185/200\n",
      "244/244 - 5s - loss: 0.3095 - accuracy: 0.9095\n",
      "Epoch 186/200\n",
      "244/244 - 5s - loss: 0.2872 - accuracy: 0.9143\n",
      "Epoch 187/200\n",
      "244/244 - 5s - loss: 0.2720 - accuracy: 0.9157\n",
      "Epoch 188/200\n",
      "244/244 - 5s - loss: 0.2681 - accuracy: 0.9143\n",
      "Epoch 189/200\n",
      "244/244 - 5s - loss: 0.2670 - accuracy: 0.9175\n",
      "Epoch 190/200\n",
      "244/244 - 5s - loss: 0.2659 - accuracy: 0.9155\n",
      "Epoch 191/200\n",
      "244/244 - 5s - loss: 0.2657 - accuracy: 0.9149\n",
      "Epoch 192/200\n",
      "244/244 - 5s - loss: 0.2662 - accuracy: 0.9167\n",
      "Epoch 193/200\n",
      "244/244 - 5s - loss: 0.2651 - accuracy: 0.9179\n",
      "Epoch 194/200\n",
      "244/244 - 5s - loss: 0.2645 - accuracy: 0.9161\n",
      "Epoch 195/200\n",
      "244/244 - 5s - loss: 0.2649 - accuracy: 0.9171\n",
      "Epoch 196/200\n",
      "244/244 - 5s - loss: 0.2646 - accuracy: 0.9162\n",
      "Epoch 197/200\n",
      "244/244 - 5s - loss: 0.2634 - accuracy: 0.9171\n",
      "Epoch 198/200\n",
      "244/244 - 5s - loss: 0.2639 - accuracy: 0.9175\n",
      "Epoch 199/200\n",
      "244/244 - 5s - loss: 0.2645 - accuracy: 0.9164\n",
      "Epoch 200/200\n",
      "244/244 - 5s - loss: 0.2644 - accuracy: 0.9164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f15bc352c10>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 10, input_length=max_len-1))\n",
    "# y데이터를 분리하였으므로 이제 X데이터의 길이는 기존 데이터의 길이 - 1\n",
    "model.add(LSTM(128))\n",
    "model.add(Dense(vocab_size, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X, y, epochs=200, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "smaller-language",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_generation(model, t, current_word, n): # 모델, 토크나이저, 현재 단어, 반복할 횟수\n",
    "    init_word = current_word # 처음 들어온 단어도 마지막에 같이 출력하기위해 저장\n",
    "    sentence = ''\n",
    "    for _ in range(n): # n번 반복\n",
    "        encoded = t.texts_to_sequences([current_word])[0] # 현재 단어에 대한 정수 인코딩\n",
    "        encoded = pad_sequences([encoded], maxlen=23, padding='pre') # 데이터에 대한 패딩\n",
    "        result = model.predict_classes(encoded, verbose=0)\n",
    "    # 입력한 X(현재 단어)에 대해서 y를 예측하고 y(예측한 단어)를 result에 저장.\n",
    "        for word, index in t.word_index.items(): \n",
    "            if index == result: # 만약 예측한 단어와 인덱스와 동일한 단어가 있다면\n",
    "                break # 해당 단어가 예측 단어이므로 break\n",
    "        current_word = current_word + ' '  + word # 현재 단어 + ' ' + 예측 단어를 현재 단어로 변경\n",
    "        sentence = sentence + ' ' + word # 예측 단어를 문장에 저장\n",
    "    # for문이므로 이 행동을 다시 반복\n",
    "    sentence = init_word + sentence\n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "floating-tokyo",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-33-4fcb1994ebdf>:7: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "i cant jump ship from facebook yet abuse better for smile\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, t, 'i', 10))\n",
    "# 임의의 단어 'i'에 대해서 10개의 단어를 추가 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "downtown-contact",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "how to make facebook more accountable i later on not ok\n"
     ]
    }
   ],
   "source": [
    "print(sentence_generation(model, t, 'how', 10))\n",
    "# 임의의 단어 'how'에 대해서 10개의 단어를 추가 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "handed-congress",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2-gpu",
   "language": "python",
   "name": "tf2-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
